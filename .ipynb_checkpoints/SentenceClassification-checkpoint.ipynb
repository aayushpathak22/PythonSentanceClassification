{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify sentences into one of several Categories, I am using a Supervised Learning mechanism, developing a model trained on a set of pre-classified sentences.\n",
    "\n",
    "Insted of  counting specific types of words (i.e. \"question words\") in the features I am considering Part-Of-Speech patterns in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CODE_LOC = 'C://Users/Aayush/Nltk-Sentence Classification'   # !! Modify to path to \"features.py\" folder lcoation\n",
    "DATA_LOC = 'C://Users/Aayush/Nltk-Sentence Classification/sentences.csv'  # !! Modify this to the CSV data location\n",
    "\n",
    "sentences = pd.read_csv(filepath_or_buffer = DATA_LOC)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry, I don't know about the weather.</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That is a tricky question to answer.</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does OCM stand for</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAX is a Mobile Application Accelerator</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can a dog see in colour?</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>how are you</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you deploy a MySQL database in the Oracle c...</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>who is dominic Fakename</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what's the weather like today?</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can the OCM host non Oracle software stacks?</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            SENTENCE CLASS\n",
       "0             Sorry, I don't know about the weather.     S\n",
       "1               That is a tricky question to answer.     C\n",
       "2                            What does OCM stand for     Q\n",
       "3            MAX is a Mobile Application Accelerator     S\n",
       "4                           Can a dog see in colour?     Q\n",
       "5                                        how are you     C\n",
       "6  If you deploy a MySQL database in the Oracle c...     Q\n",
       "7                            who is dominic Fakename     Q\n",
       "8                     what's the weather like today?     C\n",
       "9       Can the OCM host non Oracle software stacks?     Q"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below is an example of taking a sentence and extracting sets of POS-tag Triples from it. We can use this approach for building up features from a sentence by counting occurances of triple-patterns (or other POS-tag patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD', 'DT', 'NN', 'NN', 'IN', 'NN', '.']\n",
      "Words mapped to Part of Speech Tags: [('Can', 'MD'), ('a', 'DT'), ('dog', 'NN'), ('see', 'NN'), ('in', 'IN'), ('colour', 'NN'), ('?', '.')]\n",
      "PoS Tags: ['MD', 'DT', 'NN', 'NN', 'IN', 'NN', '.']\n",
      "sequences of triples: ['MD-DT-NN', 'DT-NN-NN', 'NN-NN-IN', 'NN-IN-NN']\n"
     ]
    }
   ],
   "source": [
    "# Extract some patterns of PoS sequences\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "list_of_triple_strings = []  # triple sequence of PoS tags\n",
    "sentence = \"Can a dog see in colour?\"\n",
    "\n",
    "sentenceParsed = word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(sentenceParsed)\n",
    "pos = [ i[1] for i in pos_tags ]\n",
    "print(\"Words mapped to Part of Speech Tags:\",pos_tags)\n",
    "print(\"PoS Tags:\", pos)\n",
    "\n",
    "n = len(pos)\n",
    "for i in range(0,n-3):\n",
    "    t = \"-\".join(pos[i:i+3]) # pull out 3 list item from counter, convert to string\n",
    "    list_of_triple_strings.append(t)\n",
    "    \n",
    "print(\"sequences of triples:\", list_of_triple_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can  a dog see 744  in colour\n",
      "[('Can', 'MD'), ('a', 'DT'), ('dog', 'NN'), ('see', 'NN'), ('744', 'CD'), ('in', 'IN'), ('colour', 'NN')]\n",
      "['MD-DT-NN', 'DT-NN-NN', 'NN-NN-CD', 'NN-CD-IN', 'CD-IN-NN']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(CODE_LOC)  \n",
    "import features           \n",
    "\n",
    "sentence = \"Can  \\',a dog see 744}  in colour?\"\n",
    "\n",
    "sentence = features.strip_sentence(sentence)\n",
    "print(sentence)\n",
    "pos = features.get_pos(sentence)\n",
    "print(pos)\n",
    "triples = features.get_triples(pos)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1', 'qMark': 1, 'wordCount': 6, 'stemmedCount': 4, 'qVerbCombo': 1, 'verbBeforeNoun': 1, 'VBG': 0, 'VBZ': 0, 'NNP': 0, 'NN': 3, 'NNS': 0, 'NNPS': 0, 'PRP': 0, 'CD': 0, 'stemmedEndNN': 0, 'startTuple0': 0, 'endTuple0': 1, 'endTuple1': 0, 'endTuple2': 0, 'qTripleScore': 0, 'sTripleScore': 0, 'class': 'X'}\n",
      "{'id': '2', 'qMark': 1, 'wordCount': 4, 'stemmedCount': 3, 'qVerbCombo': 1, 'verbBeforeNoun': 0, 'VBG': 1, 'VBZ': 0, 'NNP': 2, 'NN': 0, 'NNS': 0, 'NNPS': 0, 'PRP': 1, 'CD': 0, 'stemmedEndNN': 0, 'startTuple0': 0, 'endTuple0': 0, 'endTuple1': 0, 'endTuple2': 0, 'qTripleScore': 0, 'sTripleScore': 0, 'class': 'X'}\n",
      "{'id': '3', 'qMark': 0, 'wordCount': 12, 'stemmedCount': 8, 'qVerbCombo': 1, 'verbBeforeNoun': 0, 'VBG': 0, 'VBZ': 0, 'NNP': 1, 'NN': 1, 'NNS': 1, 'NNPS': 0, 'PRP': 0, 'CD': 3, 'stemmedEndNN': 0, 'startTuple0': 0, 'endTuple0': 0, 'endTuple1': 0, 'endTuple2': 0, 'qTripleScore': 0, 'sTripleScore': 2, 'class': 'X'}\n",
      "{'id': '4', 'qMark': 0, 'wordCount': 6, 'stemmedCount': 4, 'qVerbCombo': 1, 'verbBeforeNoun': 1, 'VBG': 0, 'VBZ': 0, 'NNP': 0, 'NN': 0, 'NNS': 0, 'NNPS': 0, 'PRP': 0, 'CD': 1, 'stemmedEndNN': 0, 'startTuple0': 0, 'endTuple0': 0, 'endTuple1': 1, 'endTuple2': 0, 'qTripleScore': 4, 'sTripleScore': 0, 'class': 'X'}\n"
     ]
    }
   ],
   "source": [
    "#### Bespoke Features Generator Example - Get a Python Dictionary of Features ####\n",
    "sentences = [\"Can a dog see in colour?\",\n",
    "             \"Hey, How's it going?\",\n",
    "             \"Oracle 12.2 will be released for on-premises users on 15 March 2017\",\n",
    "             \"When will Oracle 12 be released\"]\n",
    "id = 1\n",
    "for s in sentences:\n",
    "    features_dict = features.features_dict(str(id),s)\n",
    "    features_string,header = features.get_string(str(id),s)\n",
    "    print(features_dict)\n",
    "    #print(features_string)\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 rows loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "FNAME = 'featuresDump.csv' # !! Modify this to the CSV data location\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer = FNAME, )   \n",
    "print(str(len(df)), \"rows loaded\")\n",
    "\n",
    "\n",
    "df.columns = df.columns[:].str.strip()\n",
    "df['class'] = df['class'].map(lambda x: x.strip())\n",
    "\n",
    "width = df.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77  rows split into training set, 23 split into test set.\n",
      "FEATURES = Index(['wordCount', 'stemmedCount', 'stemmedEndNN', 'CD', 'NN', 'NNP', 'NNPS',\n",
      "       'NNS', 'PRP', 'VBG', 'VBZ', 'startTuple0', 'endTuple0', 'endTuple1',\n",
      "       'endTuple2', 'verbBeforeNoun', 'qMark', 'qVerbCombo', 'qTripleScore',\n",
      "       'sTripleScore'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#split into test and training (is_train: True / False col)\n",
    "np.random.seed(seed=1)\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "print(str(len(train)), \" rows split into training set,\", str(len(test)), \"split into test set.\")\n",
    "\n",
    "features = df.columns[1:width-1]  #remove the first ID col and last col=classifier\n",
    "print(\"FEATURES = {}\".format(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit an RF Model for \"class\" given features\n",
    "clf = RandomForestClassifier(n_jobs=2, n_estimators = 100)\n",
    "clf.fit(train[features], train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict against test set\n",
    "preds = clf.predict(test[features])\n",
    "predout = pd.DataFrame({ 'id' : test['id'], 'predicted' : preds, 'actual' : test['class'] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds   C  Q   S\n",
      "actual          \n",
      "C       3  0   0\n",
      "Q       0  8   1\n",
      "S       1  0  10\n",
      "\n",
      " preds        C      Q      S\n",
      "actual                      \n",
      "C       100.00   0.00   0.00\n",
      "Q         0.00  88.89  11.11\n",
      "S         9.09   0.00  90.91\n",
      "\n",
      "\n",
      "Accuracy Score:  0.913\n"
     ]
    }
   ],
   "source": [
    "## Cross-check accuracy ##\n",
    "print(pd.crosstab(test['class'], preds, rownames=['actual'], colnames=['preds']))\n",
    "print(\"\\n\",pd.crosstab(test['class'], preds, rownames=['actual']\n",
    "                       , colnames=['preds']).apply(lambda r: round(r/r.sum()*100,2), axis=1) )\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"\\n\\nAccuracy Score: \", round(accuracy_score(test['class'], preds),3) ) # https://en.wikipedia.org/wiki/Jaccard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['e8af070019393e21', 3, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 'Q'], ['cb2bfe367a7f5bfe', 6, 4, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 'Q'], ['30c3a9b0a23a6365', 9, 5, 1, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 'Q'], ['8f285b6ab8472a48', 8, 5, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 'Q'], ['ce34f3fa53325140', 5, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 'Q'], ['8c07862921357acb', 8, 6, 1, 0, 3, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['3bc89e0e912eb455', 10, 6, 1, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 'Q'], ['1fe20f36f120eda2', 7, 5, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['6f861882dbd754e0', 9, 6, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['4b26e82ce2c72a57', 10, 6, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['93443ca750695c0b', 10, 7, 1, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['33a7957acaea7387', 10, 7, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['66aac453dafccb39', 11, 6, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 'Q'], ['32faa418fa3ddffe', 6, 3, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 'Q'], ['3522718f456aeab4', 7, 4, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 'Q'], ['a82e76ebffa79a47', 5, 3, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'Q'], ['e86a9fcaa6c1eab1', 9, 7, 1, 0, 0, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 'C'], ['f2b7c832bc14b726', 8, 6, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 'S'], ['c5a6c066a9abd2f1', 19, 13, 0, 1, 2, 4, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 4, 'S'], ['5eabb6bfcd20563d', 29, 12, 1, 0, 3, 1, 0, 2, 4, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 'S'], ['662599f33c0ddaeb', 44, 23, 0, 1, 7, 2, 0, 4, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 'S'], ['63e2a7ee933f6daa', 17, 10, 1, 0, 2, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 'S'], ['693b280a9a3230b9', 24, 14, 1, 0, 3, 3, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 4, 'S'], ['c690e57869cd039f', 12, 9, 1, 0, 5, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'S'], ['9ad7ce336f3d4704', 14, 9, 1, 0, 4, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 'S'], ['a1acca44f71272ec', 15, 11, 1, 0, 1, 4, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'S'], ['ffb147cb49ec6a39', 10, 6, 1, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2, 'S'], ['55bf1c090f4d1388', 8, 5, 0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'S'], ['574cfbce34cdfdcb', 15, 10, 0, 0, 6, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 'S'], ['97b54413ba02b381', 10, 7, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'S'], ['fbc86831dbe64649', 11, 6, 1, 0, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 'S'], ['e6d42706d0798488', 10, 6, 0, 0, 3, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 'S'], ['6f48f1e8d402b07d', 28, 19, 0, 1, 3, 8, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 'S'], ['b58292dfc390a48b', 4, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'C'], ['0e9cf0b845766c7d', 5, 4, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'C'], ['d78b30df0882c623', 8, 4, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 'C'], ['014e38df4b8e013c', 4, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'C'], ['17dc01aaf5416be0', 4, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'C'], ['3c440feaf172564f', 4, 3, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'C'], ['5c484449e24df3d5', 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'C'], ['79efe2f064a4d45a', 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'C'], ['6f52f978df49d00c', 5, 4, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'C'], ['61e087cc614c897e', 5, 3, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'C'], ['03109a707fef300b', 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 'C'], ['8e066cbdfb03811f', 5, 3, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'C'], ['6a14085763143ceb', 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 'C'], ['7d8096207460670d', 5, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 'C'], ['9faad3c597a9ae4f', 2, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 'C'], ['134f71191ed2239a', 6, 3, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 'C'], ['11192c47a218c26b', 4, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 'C'], ['e44c2ab11521cb8d', 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 'C']]\n"
     ]
    }
   ],
   "source": [
    "# load in some pre-formated FAQ data in a CSV\n",
    "FNAME = 'pythonFAQ.csv' # !! Modify this to the CSV data location\n",
    "\n",
    "import csv\n",
    "import hashlib \n",
    "\n",
    "import features\n",
    "\n",
    "fin = open(FNAME, 'rt')\n",
    "reader = csv.reader(fin)\n",
    "\n",
    "keys = [\"id\",\n",
    "\"wordCount\",\n",
    "\"stemmedCount\",\n",
    "\"stemmedEndNN\",\n",
    "\"CD\",\n",
    "\"NN\",\n",
    "\"NNP\",\n",
    "\"NNPS\",\n",
    "\"NNS\",\n",
    "\"PRP\",\n",
    "\"VBG\",\n",
    "\"VBZ\",\n",
    "\"startTuple0\",\n",
    "\"endTuple0\",\n",
    "\"endTuple1\",\n",
    "\"endTuple2\",\n",
    "\"verbBeforeNoun\",\n",
    "\"qMark\",\n",
    "\"qVerbCombo\",\n",
    "\"qTripleScore\",\n",
    "\"sTripleScore\",\n",
    "\"class\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "next(reader)  #Assume we have a header \n",
    "for line in reader:\n",
    "    sentence = line[0]  \n",
    "    c = line[1]        #class-label\n",
    "    id = hashlib.md5(str(sentence).encode('utf-8')).hexdigest()[:16] # generate a unique ID\n",
    "    \n",
    "    f = features.features_dict(id,sentence, c)\n",
    "    row = []\n",
    "    \n",
    "    for key in keys:\n",
    "        value = f[key]\n",
    "        row.append(value)\n",
    "    rows.append(row)\n",
    "    \n",
    "    \n",
    "faq = pd.DataFrame(rows, columns=keys)\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict against FAQ test set\n",
    "featureNames = faq.columns[1:width-1]  #remove the first ID col and last col=classifier\n",
    "faqPreds = clf.predict(faq[featureNames])\n",
    "\n",
    "predout = pd.DataFrame({ 'id' : faq['id'], 'predicted' : faqPreds, 'actual' : faq['class'] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds    C   Q   S\n",
      "actual            \n",
      "C       12   5   2\n",
      "Q        0  14   2\n",
      "S        0   3  13\n",
      "\n",
      " preds       C      Q      S\n",
      "actual                     \n",
      "C       63.16  26.32  10.53\n",
      "Q        0.00  87.50  12.50\n",
      "S        0.00  18.75  81.25\n"
     ]
    }
   ],
   "source": [
    "## Cross-check accuracy ##\n",
    "print(pd.crosstab(faq['class'], faqPreds, rownames=['actual'], colnames=['preds']))\n",
    "\n",
    "print(\"\\n\",pd.crosstab(faq['class'], faqPreds, rownames=['actual'],\n",
    "                       colnames=['preds']).apply(lambda r: round(r/r.sum()*100,2), axis=1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.765\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score:\", round(accuracy_score(faq['class'], faqPreds) ,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction is:  QUESTION\n"
     ]
    }
   ],
   "source": [
    "textout = {'Q': \"QUESTION\", 'C': \"CHAT\", 'S':\"STATEMENT\"}\n",
    "\n",
    "# mySentence = \"Scikit-learn is a popular Python library for Machine Learning.\"\n",
    "#mySentence = \"The cat is dead\"\n",
    "mySentence = \"Is the cat dead\"\n",
    "\n",
    "myFeatures = features.features_dict('1',mySentence, 'X')\n",
    "values=[]\n",
    "for key in keys:\n",
    "    values.append(myFeatures[key])\n",
    "\n",
    "s = pd.Series(values)\n",
    "width = len(s)\n",
    "myFeatures = s[1:width-1]  #All but the last item (this is the class for supervised learning mode)\n",
    "predict = clf.predict([myFeatures])\n",
    "\n",
    "print(\"\\n\\nPrediction is: \", textout[predict[0].strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
